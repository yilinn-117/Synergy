{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prior knowledge of dimension of furniture:\n",
    "dimensions = {'couch':[2.5,.75],\n",
    "              'chair':[1,1],\n",
    "              'vase':[0.3,1.2],\n",
    "              'bowl':[0.1,0.1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AreaEstimator:\n",
    "    def __init__(self, image_path, dimensions, conf_thres = 0.5, given_length = None, given_ref = None):\n",
    "        self.image_path = image_path\n",
    "        self.conf_thres = conf_thres\n",
    "        self.dimensions = dimensions\n",
    "        if given_length and given_ref:\n",
    "            self.given_length = given_length\n",
    "            self.given_ref = given_ref\n",
    "        self.model = YOLO('yolov8m.pt')\n",
    "        self.result = self.model.predict(image_path)\n",
    "    \n",
    "    def est_area(self, target_area):\n",
    "        detected_objects = pd.DataFrame({\n",
    "            'Category': self.result[0].boxes.cls.tolist(),\n",
    "            'Confidence': self.result[0].boxes.conf.tolist(),\n",
    "            'Coordinates': self.result[0].boxes.xyxy.tolist()\n",
    "        })\n",
    "        detected_objects['Category'] = detected_objects['Category'].map(self.result[0].names)\n",
    "\n",
    "        prob_ratio = []\n",
    "\n",
    "        for index, row in detected_objects.iterrows():\n",
    "            if row['Confidence'] > self.conf_thres and row['Category'] in self.dimensions:\n",
    "                hori_ratio = self.dimensions[row['Category']][0]/(row['Coordinates'][2]-row['Coordinates'][0])\n",
    "                vert_ratio = self.dimensions[row['Category']][1]/(row['Coordinates'][3]-row['Coordinates'][1])\n",
    "\n",
    "                prob_ratio.append(hori_ratio)\n",
    "                prob_ratio.append(vert_ratio)\n",
    "\n",
    "        ratio = np.mean(prob_ratio)\n",
    "        est = (target_area[2]-target_area[0]) * ratio * (target_area[3]-target_area[1]) * ratio\n",
    "        #print(prob_ratio)\n",
    "        #print(ratio)\n",
    "        print(f'The selcted area is {est} m2')\n",
    "        \n",
    "    \n",
    "    def est_with_given(self, target_area):\n",
    "        assert self.given_length is not None and self.given_ref is not None, \"Given refer length must not be None\"\n",
    "        ratio = self.given_length/abs(self.given_ref[1]-self.given_ref[0])\n",
    "        est = (target_area[2]-target_area[0]) * ratio * (target_area[3]-target_area[1]) * ratio\n",
    "        #print(ratio)\n",
    "        print(f'The selcted area is {est} m2')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 c:\\Users\\Teddywolf\\iCloudDrive\\\\Synergy\\Synergy\\livingroom_unmarked.jpg: 384x640 2 bowls, 1 chair, 2 couchs, 3 potted plants, 3 vases, 737.0ms\n",
      "Speed: 3.0ms preprocess, 737.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "The selcted area is 1.1546018661533597 m2\n"
     ]
    }
   ],
   "source": [
    "#cropped pic is (1093,629), original is (4800,2754) \n",
    "\n",
    "target_pic = AreaEstimator(\"./livingroom_unmarked.jpg\", dimensions, given_length=1.5, given_ref=[1258*1093/4800, 2291*629/2754])\n",
    "\n",
    "\n",
    "target_pic.est_area([775*1093/4800, 568*629/2764, 1775*1093/4800, 1192*629/2764])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The selcted area is 1.2975075807757552 m2\n"
     ]
    }
   ],
   "source": [
    "target_pic.est_with_given([775*1093/4800, 568*629/2764, 1775*1093/4800, 1192*629/2764])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
